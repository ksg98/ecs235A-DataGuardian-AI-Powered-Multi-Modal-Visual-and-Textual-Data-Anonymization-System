{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Code Overview\n",
        "\n",
        "This script performs the following tasks:\n",
        "\n",
        "1. **Directory Setup**:\n",
        "   - Defines the base path and creates subdirectories for `data`, `content`, and `outputs` if they do not already exist.\n",
        "   - Specifies a `project.yaml` file path within the `content` directory.\n",
        "\n",
        "2. **Custom Entity Recognizers with Presidio**:\n",
        "   - Uses the `presidio_analyzer` library to define custom recognizers for detecting specific entities in text.\n",
        "   - Each recognizer extends the `EntityRecognizer` class and implements:\n",
        "     - **`load` Method**: Placeholder for loading necessary resources.\n",
        "     - **`analyze` Method**: Scans text for specific patterns or characteristics (e.g., numbers, emails) and returns results with confidence scores.\n",
        "\n",
        "3. **Recognizers Implemented**:\n",
        "   - **`PERSONNAMERECOGNIZER`**: Detects names based on a deny list (e.g., \"Mr.\", \"Mrs.\").\n",
        "   - **`NUMBERRECOGNIZER`**: Detects numerical tokens with a confidence score of 0.2.\n",
        "   - **`PHONENUMBERRECOGNIZER`**: Detects tokens resembling phone numbers.\n",
        "   - **`CREDITCARDRECOGNIZER`**: Identifies tokens resembling credit card numbers.\n",
        "   - **`EMAILRECOGNIZER`**: Detects email-like tokens.\n",
        "   - **`URLRECOGNIZER`**: Detects URL-like tokens.\n",
        "\n",
        "Each recognizer leverages `Presidio NLP Artifacts` to analyze tokens and generate `RecognizerResult` objects containing the identified entity type, its location in the text, and a confidence score.\n",
        "\n",
        "This script is foundational for building text analysis pipelines that identify sensitive information, such as PII (Personally Identifiable Information), using customizable rules and patterns.\n"
      ],
      "metadata": {
        "id": "lKLs_168LbXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 - Path configurations\n",
        "import os\n",
        "\n",
        "BASEPATH = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
        "DATAPATH = os.path.join(BASEPATH, \"data\")\n",
        "CONTENTPATH = os.path.join(BASEPATH, \"content\")\n",
        "OUTPUTSPATH = os.path.join(BASEPATH, \"outputs\")\n",
        "PROJECTFILEPATH = os.path.join(CONTENTPATH, \"project.yaml\")\n",
        "\n",
        "# Create necessary directories\n",
        "for path in [DATAPATH, CONTENTPATH, OUTPUTSPATH]:\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "# Cell 10 - Entity Recognizers\n",
        "from presidio_analyzer import EntityRecognizer, RecognizerResult, PatternRecognizer\n",
        "from presidio_analyzer.nlp_engine import NlpArtifacts\n",
        "from typing import List\n",
        "\n",
        "PERSONNAMERECOGNIZER = PatternRecognizer(supported_entity=\"PERSON\",\n",
        "                                        deny_list=[\"Mr.\", \"Mrs.\", \"Miss\"])\n",
        "\n",
        "class NUMBERRECOGNIZER(EntityRecognizer):\n",
        "    expected_confidence_level = 0.2\n",
        "    def load(self)->None:\n",
        "        pass\n",
        "    def analyze(self,\n",
        "                text:str,\n",
        "                entities:List[str],\n",
        "                nlp_artifacts:NlpArtifacts)->List[RecognizerResult]:\n",
        "        results = []\n",
        "        for tk in nlp_artifacts.tokens:\n",
        "            if tk.like_num:\n",
        "                result = RecognizerResult(entity_type=\"NUMBER\",\n",
        "                                        start=tk.idx,\n",
        "                                        end=tk.idx+len(tk),\n",
        "                                        score=self.expected_confidence_level)\n",
        "                results.append(result)\n",
        "        return results\n",
        "\n",
        "class PHONENUMBERRECOGNIZER(EntityRecognizer):\n",
        "    expected_confidence_level = 0.2\n",
        "    def load(self)->None:\n",
        "        pass\n",
        "    def analyze(self,\n",
        "                text:str,\n",
        "                entities:List[str],\n",
        "                nlp_artifacts:NlpArtifacts)->List[RecognizerResult]:\n",
        "        results = []\n",
        "        for tk in nlp_artifacts.tokens:\n",
        "            if tk.like_num:\n",
        "                result = RecognizerResult(entity_type=\"PHONE_NUMBER\",\n",
        "                                        start=tk.idx,\n",
        "                                        end=tk.idx+len(tk),\n",
        "                                        score=self.expected_confidence_level)\n",
        "                results.append(result)\n",
        "        return results\n",
        "\n",
        "class CREDITCARDRECOGNIZER(EntityRecognizer):\n",
        "    expected_confidence_level = 0.2\n",
        "    def load(self)->None:\n",
        "        pass\n",
        "    def analyze(self,\n",
        "                text:str,\n",
        "                entities:List[str],\n",
        "                nlp_artifacts:NlpArtifacts)->List[RecognizerResult]:\n",
        "        results = []\n",
        "        for tk in nlp_artifacts.tokens:\n",
        "            if tk.like_num:\n",
        "                result = RecognizerResult(entity_type=\"CREDIT_CARD\",\n",
        "                                        start=tk.idx,\n",
        "                                        end=tk.idx+len(tk),\n",
        "                                        score=self.expected_confidence_level)\n",
        "                results.append(result)\n",
        "        return results\n",
        "\n",
        "class EMAILRECOGNIZER(EntityRecognizer):\n",
        "    expected_confidence_level = 0.2\n",
        "    def load(self)->None:\n",
        "        pass\n",
        "    def analyze(self,\n",
        "                text:str,\n",
        "                entities:List[str],\n",
        "                nlp_artifacts:NlpArtifacts)->List[RecognizerResult]:\n",
        "        results = []\n",
        "        for tk in nlp_artifacts.tokens:\n",
        "            if tk.like_email:\n",
        "                result = RecognizerResult(entity_type=\"EMAIL_ADDRESS\",\n",
        "                                        start=tk.idx,\n",
        "                                        end=tk.idx+len(tk),\n",
        "                                        score=self.expected_confidence_level)\n",
        "                results.append(result)\n",
        "        return results\n",
        "\n",
        "class URLRECOGNIZER(EntityRecognizer):\n",
        "    expected_confidence_level = 0.2\n",
        "    def load(self)->None:\n",
        "        pass\n",
        "    def analyze(self,\n",
        "                text:str,\n",
        "                entities:List[str],\n",
        "                nlp_artifacts:NlpArtifacts)->List[RecognizerResult]:\n",
        "        results = []\n",
        "        for tk in nlp_artifacts.tokens:\n",
        "            if tk.like_url:\n",
        "                result = RecognizerResult(entity_type=\"URL\",\n",
        "                                        start=tk.idx,\n",
        "                                        end=tk.idx+len(tk),\n",
        "                                        score=self.expected_confidence_level)\n",
        "                results.append(result)\n",
        "        return results"
      ],
      "metadata": {
        "id": "pQRr_TQ6b6aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11 - Model Message Creation\n",
        "class CreateModelMessage(object):\n",
        "    def __init__(self)->CLASSINIT:\n",
        "        self.promptDict = dict()\n",
        "        self.promptDict[\"role\"] = \"user\"\n",
        "        self.promptDict[\"content\"] = []\n",
        "        self.defaultPromptIDX = (\n",
        "            \"Give very clear answers to each question. \"\n",
        "            \"Do not add your comment. \"\n",
        "            \"Question asked to you:\\n\"\n",
        "        )\n",
        "\n",
        "    def __str__(self)->str:\n",
        "        return \"Creating Model Message - Pre/Script\"\n",
        "\n",
        "    def __call__(self)->NULL | None:\n",
        "        return None\n",
        "\n",
        "    def __getstate__(self)->ERROR:\n",
        "        ERRORMODULE().Default()\n",
        "\n",
        "    def __repr__(self)->DOCUMENTATION:\n",
        "        return CreateModelMessage.__doc__\n",
        "\n",
        "    def Get(self, initPrompt:str, imageCodecPath:IMAGE | str)->dict:\n",
        "        codecImage = TRANSFORMBASE64(imageCodecPath)\n",
        "        self.defaultPromptIDX += str(initPrompt)\n",
        "        self.promptDict[\"content\"].append(CREATEINPUTURL(codecImage))\n",
        "        self.promptDict[\"content\"].append(CREATEINPUTTEXT(self.defaultPromptIDX))\n",
        "        return self.promptDict\n"
      ],
      "metadata": {
        "id": "k8PmjAX6b7ru"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}